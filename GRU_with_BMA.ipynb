{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzESoNjfJqEMhVTzjFGq4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshiga-tn7/Projects/blob/main/GRU_with_BMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "ssqiSlROhU6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO2S15CRecHl",
        "outputId": "9f0e940d-4db2-4e4d-a4e5-63c02993aac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File loaded successfully as CSV!\n",
            "                                                 url     status\n",
            "0                                   br-icloud.com.br  malicious\n",
            "1                mp3raid.com/music/krizz_kaliko.html     benign\n",
            "2                    bopsecrets.org/rexroth/cr/1.htm     benign\n",
            "3  http://www.garage-pirenne.be/index.php?option=...  malicious\n",
            "4  http://adventure-nicaragua.net/index.php?optio...  malicious\n",
            "Dataset after dropping missing values: (211954, 2)\n",
            "TF-IDF transformation complete. Feature shape: (211954, 500)\n",
            "Data Splitting Complete:\n",
            "Training Data: (169563, 500), Testing Data: (42391, 500)\n",
            "Preprocessing Done! Files saved as X_train.npy, X_test.npy, y_train.npy, y_test.npy.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Load the dataset as a CSV file\n",
        "file_path = 'dataset_phishing.csv.xls'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"File loaded successfully as CSV!\")\n",
        "print(data.head())  # Display first 5 rows\n",
        "\n",
        "# Step 2: Handle missing values (if any)\n",
        "data = data.dropna()\n",
        "print(f\"Dataset after dropping missing values: {data.shape}\")\n",
        "\n",
        "# Step 3: Encode the labels (convert 'benign' and 'malicious' to 0s and 1s)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['status'])  # Convert 'benign'/'malicious' to 0/1\n",
        "\n",
        "# Step 4: Text feature extraction using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Limit to 500 features\n",
        "X = vectorizer.fit_transform(data['url']).toarray()\n",
        "\n",
        "print(f\"TF-IDF transformation complete. Feature shape: {X.shape}\")\n",
        "\n",
        "# Step 5: Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data Splitting Complete:\")\n",
        "print(f\"Training Data: {X_train.shape}, Testing Data: {X_test.shape}\")\n",
        "\n",
        "# Step 6: Save the preprocessed data\n",
        "np.save('X_train.npy', X_train)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)\n",
        "\n",
        "print(\"Preprocessing Done! Files saved as X_train.npy, X_test.npy, y_train.npy, y_test.npy.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building GRU Model**"
      ],
      "metadata": {
        "id": "STtbM7ynsCUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Step 1: Load the preprocessed data\n",
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "print(\"Preprocessed data loaded successfully.\")\n",
        "print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
        "\n",
        "# Step 2: Reshape the input for GRU\n",
        "# GRU expects 3D input: (samples, timesteps, features)\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Step 3: Build the GRU model\n",
        "model = Sequential([\n",
        "    GRU(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
        "    Dropout(0.3),  # Prevent overfitting\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Step 4: Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the GRU model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "print(\"Training GRU model...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "print(\"\\nEvaluating the model on test data...\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0wdMJl-iK3m",
        "outputId": "1ee10305-bc2c-4563-9265-7526e87f2baf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed data loaded successfully.\n",
            "Training data shape: (169563, 500), Testing data shape: (42391, 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model...\n",
            "Epoch 1/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - accuracy: 0.9138 - loss: 0.2314 - val_accuracy: 0.9503 - val_loss: 0.1261\n",
            "Epoch 2/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.1276 - val_accuracy: 0.9543 - val_loss: 0.1207\n",
            "Epoch 3/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.9536 - loss: 0.1195 - val_accuracy: 0.9564 - val_loss: 0.1157\n",
            "Epoch 4/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.9566 - loss: 0.1167 - val_accuracy: 0.9590 - val_loss: 0.1135\n",
            "Epoch 5/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1121 - val_accuracy: 0.9592 - val_loss: 0.1105\n",
            "Epoch 6/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.9589 - loss: 0.1095 - val_accuracy: 0.9602 - val_loss: 0.1080\n",
            "Epoch 7/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9607 - loss: 0.1058 - val_accuracy: 0.9612 - val_loss: 0.1054\n",
            "Epoch 8/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1027 - val_accuracy: 0.9619 - val_loss: 0.1044\n",
            "Epoch 9/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9630 - loss: 0.0998 - val_accuracy: 0.9620 - val_loss: 0.1030\n",
            "Epoch 10/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9624 - loss: 0.0995 - val_accuracy: 0.9626 - val_loss: 0.1019\n",
            "Epoch 11/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9626 - loss: 0.0991 - val_accuracy: 0.9629 - val_loss: 0.1015\n",
            "Epoch 12/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.0963 - val_accuracy: 0.9634 - val_loss: 0.1001\n",
            "Epoch 13/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.0960 - val_accuracy: 0.9634 - val_loss: 0.0996\n",
            "Epoch 14/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9643 - loss: 0.0950 - val_accuracy: 0.9639 - val_loss: 0.0991\n",
            "Epoch 15/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.0931 - val_accuracy: 0.9638 - val_loss: 0.1004\n",
            "Epoch 16/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9652 - loss: 0.0926 - val_accuracy: 0.9639 - val_loss: 0.0999\n",
            "Epoch 17/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.0904 - val_accuracy: 0.9639 - val_loss: 0.0989\n",
            "Epoch 18/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.9651 - loss: 0.0922 - val_accuracy: 0.9640 - val_loss: 0.0988\n",
            "Epoch 19/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.0899 - val_accuracy: 0.9643 - val_loss: 0.0982\n",
            "Epoch 20/20\n",
            "\u001b[1m2120/2120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.0902 - val_accuracy: 0.9646 - val_loss: 0.0984\n",
            "\n",
            "Evaluating the model on test data...\n",
            "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.0979\n",
            "Test Loss: 0.0992, Test Accuracy: 0.9652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRU with Binary Monkey Optimization Algorithm**"
      ],
      "metadata": {
        "id": "cYolI5aBvycY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "# Reshape data for GRU\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Define the BNA Hyperparameter Optimization Function\n",
        "def evaluate_model(params):\n",
        "    gru_units, dropout_rate, batch_size, learning_rate = params\n",
        "\n",
        "    # Convert binary params to actual values\n",
        "    gru_units = [32, 64, 128][gru_units]\n",
        "    dropout_rate = [0.2, 0.3, 0.4][dropout_rate]\n",
        "    batch_size = [32, 64, 128][batch_size]\n",
        "    learning_rate = [0.001, 0.01, 0.1][learning_rate]\n",
        "\n",
        "    # Build the GRU model\n",
        "    model = Sequential([\n",
        "        GRU(gru_units, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=5, verbose=0)\n",
        "\n",
        "    # Evaluate model\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "# BNA Algorithm Implementation\n",
        "def binary_monkey_algorithm(population_size, iterations):\n",
        "    # Initialize population (random binary hyperparameters)\n",
        "    population = np.random.randint(0, 2, size=(population_size, 4))  # 4 hyperparameters\n",
        "    best_solution = None\n",
        "    best_fitness = 0\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "        print(f\"Iteration {iteration+1}/{iterations}\")\n",
        "        for i, monkey in enumerate(population):\n",
        "            fitness = evaluate_model(monkey)\n",
        "            print(f\"  Monkey {i+1}: {monkey} -> Accuracy: {fitness:.4f}\")\n",
        "\n",
        "            # Update best solution\n",
        "            if fitness > best_fitness:\n",
        "                best_fitness = fitness\n",
        "                best_solution = monkey.copy()\n",
        "\n",
        "        # Monkeys \"move\" by randomly flipping binary values\n",
        "        for monkey in population:\n",
        "            for j in range(len(monkey)):\n",
        "                if np.random.rand() < 0.3:  # Flip probability\n",
        "                    monkey[j] = 1 - monkey[j]\n",
        "\n",
        "    print(\"\\nBest Solution Found:\", best_solution)\n",
        "    print(\"Best Accuracy:\", best_fitness)\n",
        "    return best_solution\n",
        "\n",
        "# Run BNA to Optimize GRU Hyperparameters\n",
        "best_params = binary_monkey_algorithm(population_size=5, iterations=10)\n",
        "\n",
        "# Decode best hyperparameters\n",
        "gru_units = [32, 64, 128][best_params[0]]\n",
        "dropout_rate = [0.2, 0.3, 0.4][best_params[1]]\n",
        "batch_size = [32, 64, 128][best_params[2]]\n",
        "learning_rate = [0.001, 0.01, 0.1][best_params[3]]\n",
        "\n",
        "print(\"\\nOptimized Hyperparameters:\")\n",
        "print(f\"GRU Units: {gru_units}\")\n",
        "print(f\"Dropout Rate: {dropout_rate}\")\n",
        "print(f\"Batch Size: {batch_size}\")\n",
        "print(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "# Retrain GRU Model with Optimized Hyperparameters\n",
        "model = Sequential([\n",
        "    GRU(gru_units, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\nRetraining GRU Model with Optimized Hyperparameters...\")\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1)\n",
        "\n",
        "# Final Evaluation\n",
        "print(\"\\nEvaluating Optimized Model...\")\n",
        "final_loss, final_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Final Test Loss: {final_loss:.4f}\")\n",
        "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOIOgRIvoUiX",
        "outputId": "719e4d99-dc9f-4222-c731-bb1041399d33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/10\n",
            "  Monkey 1: [0 0 1 1] -> Accuracy: 0.9655\n",
            "  Monkey 2: [0 0 0 0] -> Accuracy: 0.9623\n",
            "  Monkey 3: [1 1 0 1] -> Accuracy: 0.9658\n",
            "  Monkey 4: [1 1 0 1] -> Accuracy: 0.9657\n",
            "  Monkey 5: [1 0 0 0] -> Accuracy: 0.9632\n",
            "Iteration 2/10\n",
            "  Monkey 1: [0 0 0 0] -> Accuracy: 0.9626\n",
            "  Monkey 2: [0 0 0 0] -> Accuracy: 0.9624\n",
            "  Monkey 3: [1 1 0 0] -> Accuracy: 0.9612\n",
            "  Monkey 4: [1 1 0 0] -> Accuracy: 0.9623\n",
            "  Monkey 5: [1 0 0 1] -> Accuracy: 0.9655\n",
            "Iteration 3/10\n",
            "  Monkey 1: [0 0 0 0] -> Accuracy: 0.9620\n",
            "  Monkey 2: [0 0 0 0] -> Accuracy: 0.9613\n",
            "  Monkey 3: [1 0 1 1] -> Accuracy: 0.9649\n",
            "  Monkey 4: [1 1 0 0] -> Accuracy: 0.9627\n",
            "  Monkey 5: [1 0 0 1] -> Accuracy: 0.9660\n",
            "Iteration 4/10\n",
            "  Monkey 1: [1 0 0 0] -> Accuracy: 0.9628\n",
            "  Monkey 2: [0 0 0 0] -> Accuracy: 0.9619\n",
            "  Monkey 3: [0 0 1 1] -> Accuracy: 0.9654\n",
            "  Monkey 4: [1 0 0 0] -> Accuracy: 0.9630\n",
            "  Monkey 5: [1 1 0 1] -> Accuracy: 0.9652\n",
            "Iteration 5/10\n",
            "  Monkey 1: [0 0 0 0] -> Accuracy: 0.9610\n",
            "  Monkey 2: [1 0 0 0] -> Accuracy: 0.9625\n",
            "  Monkey 3: [0 0 0 0] -> Accuracy: 0.9615\n",
            "  Monkey 4: [0 0 0 1] -> Accuracy: 0.9642\n",
            "  Monkey 5: [1 0 0 1] -> Accuracy: 0.9650\n",
            "Iteration 6/10\n",
            "  Monkey 1: [1 0 1 0] -> Accuracy: 0.9623\n",
            "  Monkey 2: [1 0 0 1] -> Accuracy: 0.9653\n",
            "  Monkey 3: [1 1 1 0] -> Accuracy: 0.9605\n",
            "  Monkey 4: [1 0 0 1] -> Accuracy: 0.9657\n",
            "  Monkey 5: [1 0 0 1] -> Accuracy: 0.9654\n",
            "Iteration 7/10\n",
            "  Monkey 1: [0 0 1 0] -> Accuracy: 0.9601\n",
            "  Monkey 2: [1 0 0 0] -> Accuracy: 0.9631\n",
            "  Monkey 3: [1 1 1 0] -> Accuracy: 0.9618\n",
            "  Monkey 4: [0 1 1 0] -> Accuracy: 0.9602\n",
            "  Monkey 5: [1 1 1 1] -> Accuracy: 0.9657\n",
            "Iteration 8/10\n",
            "  Monkey 1: [0 1 1 0] -> Accuracy: 0.9609\n",
            "  Monkey 2: [0 1 0 1] -> Accuracy: 0.9647\n",
            "  Monkey 3: [1 1 0 0] -> Accuracy: 0.9623\n",
            "  Monkey 4: [0 1 1 0] -> Accuracy: 0.9591\n",
            "  Monkey 5: [1 0 1 0] -> Accuracy: 0.9603\n",
            "Iteration 9/10\n",
            "  Monkey 1: [0 0 1 0] -> Accuracy: 0.9616\n",
            "  Monkey 2: [1 1 0 0] -> Accuracy: 0.9614\n",
            "  Monkey 3: [0 0 0 0] -> Accuracy: 0.9622\n",
            "  Monkey 4: [0 1 1 0] -> Accuracy: 0.9596\n",
            "  Monkey 5: [1 0 0 1] -> Accuracy: 0.9650\n",
            "Iteration 10/10\n",
            "  Monkey 1: [1 0 1 0] -> Accuracy: 0.9617\n",
            "  Monkey 2: [0 0 0 0] -> Accuracy: 0.9618\n",
            "  Monkey 3: [0 0 0 0] -> Accuracy: 0.9618\n",
            "  Monkey 4: [0 1 1 1] -> Accuracy: 0.9652\n",
            "  Monkey 5: [0 0 0 1] -> Accuracy: 0.9648\n",
            "\n",
            "Best Solution Found: [1 0 0 1]\n",
            "Best Accuracy: 0.9659833312034607\n",
            "\n",
            "Optimized Hyperparameters:\n",
            "GRU Units: 64\n",
            "Dropout Rate: 0.2\n",
            "Batch Size: 32\n",
            "Learning Rate: 0.01\n",
            "\n",
            "Retraining GRU Model with Optimized Hyperparameters...\n",
            "Epoch 1/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.1496\n",
            "Epoch 2/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.9620 - loss: 0.1016\n",
            "Epoch 3/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.0959\n",
            "Epoch 4/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9654 - loss: 0.0924\n",
            "Epoch 5/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7ms/step - accuracy: 0.9665 - loss: 0.0905\n",
            "Epoch 6/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.0884\n",
            "Epoch 7/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - accuracy: 0.9679 - loss: 0.0867\n",
            "Epoch 8/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.9678 - loss: 0.0862\n",
            "Epoch 9/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7ms/step - accuracy: 0.9678 - loss: 0.0859\n",
            "Epoch 10/10\n",
            "\u001b[1m5299/5299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.9679 - loss: 0.0850\n",
            "\n",
            "Evaluating Optimized Model...\n",
            "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1001\n",
            "Final Test Loss: 0.1013\n",
            "Final Test Accuracy: 0.9657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving The Model**"
      ],
      "metadata": {
        "id": "xG7SGhgeGPwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('gru_phishing_model.h5')\n",
        "print(\"Model saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44N08RWEGJ5H",
        "outputId": "f2dc3203-3712-486d-ca6f-725945b5fb26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    }
  ]
}